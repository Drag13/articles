# Оптимизации в вебе - дорого, сложно, и уже не нужно?

Думать о производительности веб приложений уже не нужно. Во-первых, оптимизированный код сложнее читать и поддерживать, во-вторых, это дорого, а самое главное - современных мощностей с головой хватает что бы смотреть он-лайн видео в 4к, а не то что отрисовать какой-то текст.

Если вы думаете именно так, мне есть что вам сказать.

<cut />

Давайте начнем с простого. Моя рабочая конфигурация I57200U (2.5GHz-3.10GHz), 12GB оперативной памяти, SSD + 100МБ сеть и, если честно, я редко испытываю дискомфорт, когда серфлю в интернете. Несмотря на это, каждый раз, когда я пишу код, я трачу некоторое время на обдумывание того, насколько сильно мои изменения повлияют на посетителях нашего приложения. И это вовсе не потому, что я такой красивый, а потому, что согласно данным из аналитики, большинство наших клиентов используют для заказа свои мобильные телефоны. Что, в свою очередь означает нестабильное хG соедениение (где x находится в пределах 2–4), значительно более ограниченный объем памяти (2–4 гб вместо моих 12) и процессор с условной частотой в 1.7GHz - 2GHz который и так немного занят десяткой влкадок и несколькими приложениями. Поэтому то, что летает у меня - может подтормаживать и раздражать наших пользователей. А учитывая размер минимального чека моего пользователя - я очень не хочу никого раздражать.

Именно поэтому, каждое код-ревью, я бращаю внимание на разные моменты связанные с производительностью. Моя команда - большие молодцы, потому что они терпят мои замечания и даже иногда с ними соглашаются. Но, естественно, я общаюсь не только с со своей командой, и часто, когда я говорою что производительность важна, в ответ я слышу аргументы, о которых уже упоминал - поддержка, цена работы и возросшая вычислительная мощность. И вот о них я хочу поговорить.

## 640kb хватит всем

Безусловно, мощность современных вычислительных систем просто поражает. Процессор моего смартфона в 16.(26) раз быстрее процессора моего первого компьютера с которого я вышел в интернет. И это, не говоря уже о том, что там было одно только одно ядро, а в телефоне их аж четыре плюс четыре. А ведь сайты по большому счету не изменились. HTML для содержимого, CSS для красивостей, и JS для взаимодействия. Молния не родилась из серебра, флеш похоронили, а webassembly пока все еще собирается.

Да и пропускная способность современных сетей позволяет больше не требовать формат изображения, который бы рендерился снизу вверх. Расходимся? Увы, но нет.

В 2017 году, умные ребята [провели очень интересное исследование](https://infrequently.org/2017/10/can-you-afford-it-real-world-web-performance-budgets/) согласно которому, если мы хотим влезть в пятисекундный бюджет для первичной загрузки сайта, размер наших ресурсов не должен превышать 170KB (уже сжатых), если JavaScript-а "немного", или 130KB для сайтов/приложений построенных с помощью JS фреймоворках. Почему так мало? Дело в том, что согласно исследованию 2017 года:

* 45% мобильных соединений используют 2G
* 75% **всех** соединений используют 2G или 3G

А средним телефоном была выбрана модель 2016 года [Motorola Moto G4](https://www.gsmarena.com/motorola_moto_g4-8103.php) ценой в 200 долларов с процессором Octa-core (4x1.5 GHz Cortex-A53 & 4x1.2 GHz Cortex-A53). Естественно, в таких условиях разгуляться сложно. Конечно, где 2017 год, а где 2021? Четыре года, закон Мура, и все это уже не актуально.

Поэтому в 2021 году исследование [было повторено](https://infrequently.org/2021/03/the-performance-inequality-gap/). Ситуация действительно улучшилась и теперь у нас есть аж 100Kb для HTML/CSS/Fonts + 300-350KB для JavaScript. Однако это произошло в основном благодаря сетям. Вычислительные мощности бюджетных устройств изменились слабо. Взгляните на этот график и оцените прогресс с 2017 года.

Поэтому, несмотря на весь прогресс, если мы не хотим потерять нашего среднего (пусть и абстрактного) пользователя, наш бюджет все еще довольно ограничен. А ведь тут мы говорим только о загрузке приложения. Но для SPA приложений просто загрузить ресурсы мало. Его ведь еще нужно выполнить, а уже после этого построить сам DOM и показать посетителю какой-то контент. Отчасти это нивелируется тем, что размер HTML минимален и грузится очень быстро, но JavaScript - самый дорогой ресурс в плане времени обработки, так что много мы не выигрываем. Тем более что часть бюджета уже откусил сам фреймворк.

Поэтому оптимизации с точки зрения размера начального бандла - все еще чрезвычайно очень важны. И меня сильно огорчают, когда, опытные разработчики, показывают нечто вроде такого:

```js
import * as moment from 'moment';
//...
const date = moment();
```
https://christianlydemann.com/logging-with-angular/

Вроде бы ничего плохого, наверняка в проекте у него уже стоит moment, но в качестве примера этот код действительно плох. Кто-то не посмотрел, не подумал, скопировал и вот вам, в ваш любимый проект влетает от 18 до 72Kb JavaScript (и это уже после сжатия). А ради чего? Ради единственного метода `diff`. А потом, людям приходится даже писать [спеицальные плагины](https://github.com/jmblog/how-to-optimize-momentjs-with-webpack) что бы как-то это оптимизировать.

А ведь, помимо этого, у нас еще есть стили, которые парсятся хоть и быстро, зато умеют блокировать JS. Есть еще шрифты, которые могут заставить браузер вообще не показывать текст, пока не загрузятся. А для любителей анимаций есть еще и force reflow, который просто заставляет "вот прям щас" пересчитать лаяут вашего сайта, что приводит к лагам и потери кадров. И, вишенка на торте, так называемый холодный старт TCP, который просто игнорирует весь ваш 100МБ канал и позволяет отправить первый пакет [не более чем 14KB](https://tylercipriani.com/blog/2016/09/25/the-14kb-in-the-tcp-initial-window/).

И это только проблемы загрузки. А ведь есть еще рантайм, с которым все тоже не очень радужно, особенно для SPA приложений.

Как вы знаете, JavaScript язык в основном однопоточный. С одной стороны, это большой плюс - нет нужды беспокоиться о синхронизации потоков, доступу к разделямым ресурсам и все такое. С другой стороны, ```while(true){}``` установленный где-то в начале документа убивает все настолько качественно, что вы не то что на кнопку нажать не сможете, вы даже статический контент после этого кода не увидите даже на каком нибудь [Фугаку](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%B3%D0%B0%D0%BA%D1%83). К чему это я? Да к тому, что несмотря на весь прогресс, способо выстрелить в ногу в современном вебе все еще остается предостаточно. Тут и последовательные запросы вместо параллельных, и N+1, и тяжелые regex-ы во время рендера приложения, и чрезмерная работа с DOM-ом и многие другие моменты. А ведь помимо таких в общем-то очевидных моментых (которые вы тоже не всегда отловите), есть еще и нюансы савмого фреймворка.

Например, для меня до сих пор остается загадкой, почему, по-умолчанию, функциональные компоненты вызываются всякий раз когда вызывается их родитель. Да, это легко поменять, использовав `React.memo` или перейти на `PureComponent`, но фреймворк, который позиционируется быстрым, почему то решил пойти именно таким путем. Особенно проблемным это стало после популяризации хуков, что привело к усложнению функциональных компонентов. Кстати, раз уж речь зашла про реакт - вы конечно же знаете, что реакт по-умолчанию встраивает изображение до 10kb прямо в JS код? Мы тут пока будем грузиться, а пользователь пусть подождет. Зато, если он все-таки не уйдет, картинку мы ему покажем моментально. Не уверен, что это действительно оптимальный подход. Правда его можно отключить с помощью IMAGE_INLINE_SIZE_LIMIT=0 в .env файле.

Но если вы думаете, что у Ангуляра с этим лечге то - [нет](https://betterprogramming.pub/build-me-an-angular-app-with-memory-leaks-please-36302184e658). Утечки памяти из-за сложности Rx.JS, постоянный перерендер компонентов из-за дефолтной Change Detection Strategy и многое другое приводит к тому, что некоторые вообще [отключают NgZone](https://blog.bitsrc.io/quantum-angular-maximizing-performance-by-removing-zone-e0eefe85b8d8).

Резюмируя сказанное: несмотря на то что мой смартфон может просчитать траекторию полета теслы на марс, с отображением «простого текста» у него могут быть проблемы.

Теперь перейдем к остальным аргументам.

## Оптимизированный код сложнее поддерживать

В качестве обоснования этого аргумента часто приводят нечто вроде вот такого пример:

```javascript
const names = users.map(user => user.name)
                   .filter(name => name[0] === 'a')
                   .join(' ')
```

```javascript
let names = '';
for (let i = 0; i < users.length; i++) {
    const userName = users[i].name;
    if (userName[0] === 'a') {
        names += `${userName} `;
    }
}
const result = names.trimEnd();
```

\- Мол, что тебе легче читать и поддерживать?

Я отвечаю, что первый читается легче и мой оппонент радостный уходит в закат. Но давайте будем справедливыми - не все оптимизации выглядят именно так. Ради примера возьмем тот же Реакт

Это функциональный компонент, который рендерит статический список.

```jsx
const TermsAndConditions = () => <ul>{['Don\'t be evil'].map((term, i) => <li key={i}>{term}</li>)}</ul>
```

Это его "оптимизированная" версия:

```jsx
import {rules} from './settings';
const TermsAndConditions = () => <ul>{rules.map((term, i) => <li key={term}>{term}</li>)}</ul>
```

Стало сильно сложнее? Нет, абсолютно. Зато теперь у нас статический контент лежит в настройках, а бонусом мы не создаем новый массив на каждый вызов функции (а это время на аллокацию и время на уборку мусора). Можно для него вообще перерендер выключить, но даже так уже не плохо. Спички, скажете вы? Спички, да. Но что насчет такого?

Было:
```javascript
const user = await fetch(userId);
const car = await fetch(carId);
```

Стало:
```javascript
const userRequest = fetch(userId);
const carRequest = fetch(carId);
const [user, car] = await Promise.all([userRequest, carRequest]);
```

Можно было бы еще короче написать, но короче не всегда лучше. Главное не в этом. Главное что у нас есть код благодаря которому приложение работает быстрее, а это нам не стоило почти ничего. И таких мест много! Чего стоит один code-splitting. Немного кода и куска JavaScript как небывало. Его больше не надо грузить, парсить. Все просто стало немного лучше.

К чему я веду - код, который не написан чтобы быть медленным, вполне может работать быстро. Звучит как призыв капитана очевидность, но часть проблем с производительностью я исправлял именно так - не ускоряя код, а просто устраняя медленный. Возможно, с этим подходом вы и не попадете в топ 1 самых быстрых сайтов или приложений, но, как известно, 20% усилий приводят к 80% результату, а именно это нам и надо.

## Мы не можем тратить на это время, нам в продакшн надо

И наконец последний пункт. Многие считают, что оптимизации производительности — это дорого или по времени (долго, клиент не выделит) или даже по деньгам (нужен спец, бюджета нет, когда-нибудь потом). И это, на самом деле, самый болезненный момент. Если беклог выше [Фудзиямы](https://upload.wikimedia.org/wikipedia/commons/c/c3/FujiWestView2157.jpg) (куда-то меня на восток потянуло), релиз завтра, менеджер пингует каждые два часа с прекрасным "ну как там", заниматься оптимизацией вам будет тяжело. Но есть два "но", которые я хочу проговорить.

Во-первых, многие “оптимизации” — это вовсе не оптимизации. Это просто корректно организованный код, который не тормозит. Да, есть сложные/[не очевидные](https://habr.com/ru/post/449368/) моменты, особенно на стыке приложение/инфраструктура, но, если мы будем грамотно использовать ресурсы которые у нас есть, все будет уже гораздо лучше. В конце концов JavaScript это основной инструмент в веб разработке и понимание того, что ```const really = () => ({})``` создает в памяти новый объект на каждый вызов должно быть очевидно.

А во-вторых, объяснять заказчку или ПМ-у что производительный веб нужен в первую очередь проекту это именно наша задача как специалиста. Заказчик вообще не знает, что-такое что такое эти ваши FCP, LCP, TTI, как они влияют на поведение пользователя или на рейтинг в выдаче. У него в голове может просто не быть понимания того, что быстрый веб — это точно такая же фича как, например, список рекомендуемых товаров. Почему? Потому что они оба напрямую влияют на продажи закзичка, а значит и на его доход. И вот этот аргумент заказчики понимает прекрасно.

## Так что же делать

Как ни странно, но я не предлагаю тут же бежать, удалять проект и все переделывать. Я так же не призываю душить ПМ-а или продакта. Скорее всего это не сработает. Вместо этого я предлагаю вам выбрать ключевые метрики производительности вашего приложения и начать их мониторить. Ах, да - и конечно-же информировать об этом лиц принимающих решения. Если у вас на проекто все хорошо - вам скажут что команда молодцы и вы со спокойной совестью и документальным подтверждением своих прямых рук пойдете пить нефильтрованное. А если плохо - скорее всего ПМ/Владелец сами придут к вам за решением проблемы и тогда уже вы будете говорить о сроках и объемах.

Ну а о том как мерять есть не одна статья. Можно и light-house cli использовать в CI/CD пайплайне, можно и на пюпитере руками что-то написать. Главное, если ваш основной рынок это, например Северная Америка, то не тестируйте ее из Киева, может не ловко получиться.

## Послесловие - преждевременная оптимизация — корень всех зол

Цитата из заглавия известна всем и часто приводится как 0-й аргумент против оптимизации веб приложений. Но с вебом есть один не очевидный нюанс. В вебе пользователь не жалуется, а просто молчаливо уходит. Поэтому, если вы не хотите остаться без пользователей, то оптимизацию я бы начал все таки по-раньше, во избежание. И тогда все будет хорошо.























 Причем, если часть из них очевидна, как мой пример выше, то часть может быть уже не столь очевидной. Приведу классический пример из мира реакт:

```jsx
const Btn = ({ txt }) => (
  <button onClick={() => alert("test")} type="button">
    {txt}
  </button>
);
```

Функциональный компонент выполняется(1) всякий раз когда меняется его родитель. Каждое выполнение приводит к созданию объекта который реакт будет использовать для поиска изменившихся свойств, а так же к созданию нового обработчика событий для нажатия мыши. Правда в продакшн сборке обработчик к DOM елементу добавляться не будет, и тем менее, тут явно проделывается излишняя работа. Очевидно что







Конечно, такое мне никто не говорил, хотя бы потому что для такой формулировки нужно самому поседеть за Celeronom или Atomom


слышу, что: на самом деле, в (подставьте сюда текущий год), оптимизации производительности уже не важна.

примерно те же аргументы что я написал выше - поддержка, цена работы и мощность и вот о них я хочу поговорить.



 И тем не менее, каждый раз когда я пишу код, я трачу время на обдумывание того, насколько сильно это отразиться на посетителях моего сайта. Причина этому проста - согласно аналитике большинство из них используют мобильные телефоны для того, что бы сделать заказ в нашем маленьком сервисе. А это значит что они имеет нестабильное хG соедениение (где x находится в пределах 2-4) значительно более ограниченный объем памяти (2-4 гб вместо моих 16) и процессор частотой ____ гц. Поэтоу то что летает у меня - может подтормаживать и раздражать наших пользователей. Учитывая размер минимального чека моего пользователя - я очень не хочу никого раздражать.


Самый частый аргумент который я слышу это конечно же о мощности. Мы работаем с реактом, который изначально писался с прицелом на производительность. Плюс современное мощное железо позволяет многим разработчикам уверенно говорить что все будет работать быстро. Отчасти это правда - небольшие или грамотно написанные приложения на реакте действительно работают быстро. Однако есть нюанс (С). Реакт (да и наверное многие библиотеки и фреймоворки, но реакт в этом моменте лидер) очень легко позволяет убить производительность благодаря своей модели функциональных компонент (которые тем не менее мне безумно нравятся за простоту). Давайте посмотрим на примере:

А ведь на мобильном устройстве у нас будет еще меньше памяти и вычислительных ресурсов.

Однако проблема с производительностью в рантайме это только половина проблемы. Вторая, даже более важная проблема, заключается в скорости загрузки вашего сайта или веб приложения. Вы конечно знаете, что джаваскрипт блокирует рендер документа поэтому все стараются положить его в конец документа или загружать асинхронно используя async/defer конструкции. Вы так же, конечно знаете, что css блокирует загрузку JavaScript (критический CSS). Но знаете ли вы, как размер что несмотря на ваш 100МБ канал, скорость с которой мы получаем первый пакет данных равна _____. Да, потом она вырастает но пользователь ждать не любит. Секунда, вторая и ваш клиент уже ушел, бизнес потерял свою копеечку, а вы, возможно, премию.

И это не все нуюансы. Еще есть шрифты, которые умеют блокировать рендер текста до их загрузки. Еще есть принудительный пересчет стилей (особенно больно для СПА приложений которые обращаются к ___). Есть цена подключения к другим доменам. Есть лимиты на количество параллельных соединений. И все вместе это складывается не только в плохой пользовательский опыт но и  Core Web Vitals метрики из-за которых поисковик может пессимизировать выдачу вашего сайта в поиске. А изображения?

Конечно я не открыл Америку. Эти проблемы известны, и способы лечения с ними известны. Но если вы не будете думать о производительности вашего приложения - вы даже не поймете что ваше приложение болеет.

Ну хорошо. Допустим я убиедил вас, что несмотря на прогресс, мы все еще должны задумываться о производительности наших продуктов. И тут вспылвапет второй аргумент - оптимизированный код сложнее поддерживать.

Вот сравните два куска кода, что легче для чтения и понимания? А где проще допустить ошибку?

```js
const names = users.map(user => user.name).filter(name => name[0] === 'a').join(' ')
```

```js
let names = '';
for (let i = 0; i < users.length; i++) {
    const userName = users[i].name;
    if (userName[0] === 'a') {
        names += `${userName} `;
    }
}
const result = names.trimEnd();
```

Да, первый код выглядит чище (хотя можно было бы вынести его в отдельную функцию, покрыть тестами, и забыть об этом, но, пускай). Но всегда ли оптимизации выглядят так? Возмем тот же реакт и напишем компонент для покааза списка условий пользования нашего сервиса:

```jsx
const TermsAndConditions = () => <ul>{['Don\'t be evil'].map((term, i) => <li key={i}>{term}</li>)}</ul>
```

Помимо нарушения SRP (статья не об этом), тут есть очевидная проблема. Фактически статичный список будет постоянно ререндериться (хоть, дом обновляться и не будет) и создавать новый массив в памяти на каждый рендер родителя. И скажите спасибо, что строка будет скорее всего интернирована и не будет пересоздаваться. А ведь способов убрать такое поведение есть на любой вкус - тут и `ShouldComponentUpdate false`, PureComponent, React.memo, и на худой конец, просто вынести массив за пределы компоненты куда-то в настройки. Вы скажете что я экономлю на спичках и такая оптимизация практически не даст выиграша и формально будете правы. Но спичка тут, спичка там, и вот у вас уже 500мс для слабых мобильный устройств. А главное это не стоит вам почти ничего. Код не читается хуже, он просто стал немного быстрее. Да и правило Парето никто не отменял, в том числе для performance оптимизаций.

Другими словами - скорее всего вам не понадобится оптимизировать код, который не написан что бы быть медленными.

И вот теперь приходит третий аргумент, который казалось бы пробить не возможно-
оптимизации производительно это дорого и его младший брат "заказчику мы это не продадим".

Давайте начнем с последнего, про заказчика. Сейчас я, наверное, скажу крамольную мысль, но я в нее искренне верю. Объяснять что заказчку (или ПМ-у или другому ответственному лицу) нужен производительный веб это задача ваша как программиста. Потому что только вы знаете, нужно ли ему это действительн и в каком объеме. Заказчик вообще не знает что-такое что такое LGP, LCP, etc и как они влияют. Скорее всего он понятия не имеет об эксперементах гугла и ______. У него в голове просто нет понимания того, что быстрый веб это точно такая же фича как, например, список рекомендуемых товаров. Почему? Потому что они оба напрямую влияют на продажи вашего закзичка и на его доход. И вот этот аргумент заказчик понимает прекрасно.

Ну а что касается первого аргумента тут все еще проще. Простые оптимизации, которых вам вполне могут хватить не требуют ни особой квалификации, ни больших затрат времени. Все что от вас требуется - просто не замедляйте ваше приложение.

Послесловие про 3rd party code.

Знаете как ускорить ваше приложение посто вот не сходя с места и практически не меняя кодовую базу? Посмотрите на посторонний код который вы загружаете на свою страницу. Скорее всего его объем вполне можно уменьшить. Я, например, встречал загрузку GoogleTagManager только для того что бы загрузить потом Google Analytics. Или использование сразу трех! сервисв для аналитики. Уменьшив объем посторонних скриптов вы не только повышаете производительность своего решения, но так же увличиваете его безопасность. Необязательно ломать банк, если можно взломать его доствку.



Представьте себе картину. Релиз через 3 дня. Часть задач не закрыта и пишутся в авральном порядке, команда качества делает регрессию прямо по обновляемому коду до 12 ночи. И тут прихожу я, весь в белом, и говорю - а вот тут у вас код не оптимальный-с, извольте ка переделать. Мне кажется так далеко даже Мильфгард не ездил.


## И что теперь?

Как ни странно, но я не предлагаю тут же бежать, удалять проект и все переделывать. Я так же не призываю душить ПМ-а или кто там у вас отвечает за прибыль проекта в целом. Скорее всего это попросту не сработает. Вместо этого я предлагаю вам выбрать ключевые метрики производительности и начать их мониторить. Ах, да - и конечно-же информировать об этом лиц принимающих решения. Если у вас на проекто все хорошо - все скажут что команда молодцы и вы со спокойной совестью и документальным подтверждением своих прямых рук пойдете пить вио. А если плохо - скорее всего ПМ/Владелец сами придут к вам за решением и тогда уже вы будете говорить о сроках и объемах.

Ну а о том как мерять есть не одна статья. Главное, если ваш основной рынок это, например южная Америка, меряйте оттуда. А то мы это уже проходили. Сервер в Европе, тесты хорошие, а на условной Ямайке все грузится минуту.

 и вторая половина не только важна не меньше, но




 просто на корню благодаря:

* Реакт это библиотека* а не фреймворк
* Функциональные компоненты по-умолчанию выполняются всякий раз когда рендерится их родитель

Наверное мой первый аргумент звучит для вас очень странно однако я прошу вас подумать вот о чем. Всякий раз когда вам нужна дополнительная функциональность, вы идете в npm и ставите дополнительный пакет. Это, конечно, не плохо, но это вырабатывают плохую привычку ставить сторонние решения на каждую, даже небольшую потребность тем самым раздувая ваш бандл. Парадокс в том, что это еще и сильная сторона реакта, т.к. позволяет добавлять исключительно то что нужно, а не все подряд. Ангуляр потратил много времени что-бы убрать из кор модуля не обязательные зависимости.


И хорошо если вы смотрите не только на звезды, а и например на bundlephobia. Но некоторые настолько привыкли к таком

, однако я вижу проблему вот в чем. Когда вам понадобится дополнительная функциональность


(примеры сейчас будут). И что самое грустное - многие примеры кода имеют именно эти проблемы.

Давайте посмотрим на пример №1:

```jsx
const label = ({txt})=> <label>{txt}</label>
```

Дл

 (виртуальный дом, файбер, постоянное уменьшение размера кор библиотеки)



Наверное, примерно так, думали инженеры гугла когда выкатили свою обновленную версию почты, которая отъедала гигабайты памяти и висла.