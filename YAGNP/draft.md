![](https://habrastorage.org/webt/kh/no/az/khnoaz9k44nlpihpytorvognvek.jpeg)

Разработчикам больше не нужно думать об оптимизации веб-приложений. Во-первых, оптимизированный код сложнее читать и поддерживать, во-вторых, это дорого, а самое главное - современных мощностей с головой хватает что бы смотреть онлайн видео в 4к, а не то что отрисовать какой-то текст.

Если вы думаете именно так, мне есть что вам сказать.

<cut />

Давайте начнем с простого. Конфигурация с которой я пишу эту статью - I57200U (2.5GHz-3.10GHz), 12GB оперативной памяти, SSD + 100МБ (провайдер так говорит, но мне кажется врет) сеть и, если честно, я редко испытываю дискомфорт, когда серфлю в интернете. Несмотря на это, каждый раз, когда я пишу код, я трачу некоторое время на обдумывание того, насколько сильно мои изменения повлияют на посетителей приложений, которые я разрабатываю. И это вовсе не потому, что я такой красивый, а потому, что согласно данным аналитики, большинство наших клиентов используют для заказа свои мобильные телефоны. Что, в свою очередь означает нестабильное хG соедениение (где x находится в пределах 2–4), значительно более ограниченный объем памяти (2–4 GB вместо моих 12) и процессор с условной частотой в 1.7GHz - 2GHz который и так чуточку занят десятком-другим вкладок и пятеркой приложений. Поэтому то, что у меня работает нормально - может подтормаживать и раздражать наших пользователей. А учитывая размер минимального чека моего пользователя - я очень не хочу никого раздражать.

Именно поэтому, каждое код-ревью, я бращаю внимание на разные моменты связанные с производительностью. Моя команда - большие молодцы, потому что они терпят мои замечания и даже иногда с ними соглашаются. Но, естественно, я общаюсь не только с со своей командой, и часто, когда я говорою что производительность в вебе все еще важна, в ответ я слышу аргументы, о которых уже упоминал - поддержка, цена работы и возросшая вычислительная мощность. И вот о них я хочу поговорить.

## 640kb хватит всем

Безусловно, мощность современных вычислительных систем просто поражает. Процессор моего смартфона в 16,(26) раз быстрее процессора моего первого компьютера с которого я вышел в интернет. И это, не говоря уже о том, что там было только одно ядро, а в телефоне их целых четыре плюс четыре. А ведь сайты по большому счету не изменились. HTML для содержимого, CSS для красивостей, и JS для взаимодействия. Как мы знаем, из серебра не родилась молния, флеш не быстро, но тоже похоронили, а webassembly все еще в сборке. Да и пропускная способность современных сетей позволяет больше не требовать формат изображения, который бы рендерился снизу вверх. Расходимся? Увы, но нет.

В 2017 году, умные ребята [провели очень интересное исследование](https://infrequently.org/2017/10/can-you-afford-it-real-world-web-performance-budgets/) согласно которому, если мы хотим влезть в пятисекундный бюджет для первичной загрузки сайта, размер наших ресурсов не должен превышать 170KB (уже сжатых), если JavaScript-а "немного", или 130KB для сайтов/приложений построенных с помощью JS фреймоворках. Почему так мало? Дело в том, что согласно исследованию 2017 года:

* 45% мобильных соединений используют 2G
* 75% **всех** соединений используют 2G или 3G
* А усредненным телефоном был выбран [Motorola Moto G4](https://www.gsmarena.com/motorola_moto_g4-8103.php) ценою в 200 долларов с процессором Octa-core (4x1.5 GHz Cortex-A53 & 4x1.2 GHz Cortex-A53)

Естественно, в таких условиях разгуляться сложно, поэтому бюджет и выглядит так скромно. Однако с тех пор уже прошло четыре года и в поэтому в 2021 году исследование [было повторено](https://infrequently.org/2021/03/the-performance-inequality-gap/). Ситуация действительно улучшилась и теперь у нас есть 100Kb для HTML/CSS/Fonts + 300-350KB для пожатого JavaScript. Однако это произошло в основном благодаря сетям. Вычислительные мощности бюджетных устройств изменились слабо. Взгляните на этот график и оцените прогресс с 2017 года.

[![](https://infrequently.org/2021/03/the-performance-inequality-gap/single_core_scores_large.png)](https://infrequently.org/2021/03/the-performance-inequality-gap/single_core_scores_large.png)

Мы видим, что IPhone показывают стабильный рост, но вот остальные производители нажимают на педаль газа весьма осторожно. А ведь не айфоном единым жив мобильный веб. Кстати, когда я говорю "мобильный веб" пожайлуйста, не думайте, что речь идет только об условно дешевых смартфонах. Вот скриншоты нескольких ноутбуков за уже ~350 долларов.

![](https://habrastorage.org/webt/vh/bu/d8/vhbud8uio-pxexqbggi_dw8iog8.png)

Первая модель - всего 4GB DDR4, двухъядерный Intel Celeron N4020 (1.1–2.8 ГГц) - такое точно так же не даст вам особо разгуляться. А ведь еще есть огромное количество просто устаревшей, 10-и и даже 15-летней техники в офисах и домах. Если добавить немного драммы, можно сказать, что игнорируя производительность своего сайта или приложения, вы просто отказываетесь от этих пользователей.

Поэтому, несмотря на весь прогресс, если мы не хотим потерять нашего среднего пользователя, наш бюджет все еще довольно ограничен. А ведь тут мы говорим только о загрузке приложения. Но для SPA приложений просто загрузить ресурсы мало. Еще нужно выполнить JavaScript, и только потом, основываясь на вычислениях, отрисовать пользователю какой-то контент, а на слабых машинах это может немного помедленнее. Впрочем хватит теории, давайте посмотрим на реальные примеры.

Вот это сравнительный график для нашего приложения с прода без замедления CPU  и с 6-и кратным замедлением.

![my](https://habrastorage.org/webt/qw/tj/8r/qwtj8rzljs94sfadrbttzxfj2cc.png)

Как видим, время работы скриптов увеличилось с 362 милисекунд до 2102 милисекунд, т.е. в примерно в 5.8 раза. И это для скромных, 253Kb JavaScript, а Largest-Contentful-Paint событие (не самый лучший ориентир, но подойдет) сдвинулось с 2.2 секунд до 4.7 секунд.

А вот такая же таблица но уже для Хабра (оговорюсь сразу, что мне пришлось отключить яндекс аналитику и вк, просто что бы я смог дождаться хотя бы каких-то данных).

Поэтому оптимизации с точки зрения размера начального бандла - все еще чрезвычайно  важны. И меня сильно огорчают, когда, опытные разработчики, в обучающих статья пишут нечто вроде [такого](https://christianlydemann.com/logging-with-angular/):

```javascript
import * as moment from 'moment';
//...
const date = moment();
const requestDuration = moment().diff(startMoment, 'milliseconds');
```

Т.е. я все понимаю, скорее всего в проекте у автора уже стоит moment, поэтому его использование здесь наверняка оправдано. Но черт побери, это же учебный пример! Кто-то не посмотрел, как всегда не подумал, скопировал и вот вам, в ваш любимый проект влетает от 18 до 72Kb JavaScript (и это уже после сжатия). А ради чего? Ради единственного метода `diff`. А потом, людям приходится даже писать [спеицальные плагины](https://github.com/jmblog/how-to-optimize-momentjs-with-webpack) что бы как-то это оптимизировать. И такие примеры, без предупреждений, без сносок о том, почему это может быть плохо - они повсюду. Авторы статей, блогов и курсов, в погоне за простотой кода и аудиторией, приучают других разработчиков игнорировать производительность как класс.

А помимо просто размера есть и другие нюансы. У нас еще есть стили, которые парсятся хоть и быстро, зато умеют [блокировать JS](https://web.dev/extract-critical-css/). Есть еще шрифты, которые могут заставить браузер вообще не показывать текст, пока не загрузятся. Для любителей анимаций есть еще и [force reflow](https://gist.github.com/paulirish/5d52fb081b3570c81e3a), который просто заставляет "вот прям щас" пересчитать лаяут вашего сайта, что приводит к лагам и потери кадров. И, вишенка на торте, так называемый холодный старт TCP, который просто игнорирует весь ваш 100МБ канал и позволяет отправить первый пакет [не более чем 14KB](https://tylercipriani.com/blog/2016/09/25/the-14kb-in-the-tcp-initial-window/).

И это только проблемы загрузки. А ведь есть еще рантайм, с которым все тоже не очень радужно, особенно для SPA приложений.

Как вы знаете, JavaScript язык в основном однопоточный. С одной стороны, это большой плюс - нет нужды беспокоиться о синхронизации потоков, доступу к разделямым ресурсам и все такое. С другой стороны, ```while(true){}``` установленный где-то в начале документа убивает все настолько качественно, что вы не то что на кнопку нажать не сможете, вы даже статический контент после этого кода не увидите даже на каком нибудь [Фугаку](https://ru.wikipedia.org/wiki/%D0%A4%D1%83%D0%B3%D0%B0%D0%BA%D1%83). К чему это я? Да к тому, что несмотря на весь прогресс, способо выстрелить в ногу в современном вебе все еще остается предостаточно. Тут и последовательные запросы вместо параллельных, и N+1 прямо с юая, и тяжелые regex-ы во время рендера приложения, и чрезмерная работа с DOM-ом и многие другие моменты. А ведь помимо таких, в общем-то очевидных моментов, (которые вы тоже не всегда отловите), есть еще и нюансы самого фреймворка.

Например, для меня до сих пор остается загадкой, почему, по-умолчанию, функциональные компоненты вызываются всякий раз, когда вызывается их родитель. Да, это легко поменять, использовав `React.memo` или перейти на `PureComponent`, но фреймворк, который позиционируется быстрым, почему-то решил пойти именно таким путем. Особенно проблемным это стало после популяризации хуков, что привело к усложнению функциональных компонентов. Кстати, раз уж речь зашла про Реакт - вы конечно же знаете, что реакт по-умолчанию встраивает изображение до 10kb прямо в JS код? Мы тут пока будем грузиться, а пользователь пусть подождет. Зато, если он все-таки не уйдет, картинку мы ему покажем моментально. Не уверен, что это действительно оптимальный подход (отключается с помощью IMAGE_INLINE_SIZE_LIMIT=0 в .env файле).

Но если вы думаете, что у Ангуляра с этим лечге то - [нет](https://betterprogramming.pub/build-me-an-angular-app-with-memory-leaks-please-36302184e658). Утечки памяти из-за сложности Rx.JS, постоянный перерендер компонентов из-за дефолтной Change Detection Strategy и многое другое приводит к тому, что некоторые вообще [отключают NgZone](https://blog.bitsrc.io/quantum-angular-maximizing-performance-by-removing-zone-e0eefe85b8d8).

Резюмируя сказанное: несмотря на то что, мой смартфон может просчитать траекторию полета теслы на марс, с отображением «простого текста» у него могут быть проблемы.

Теперь перейдем к остальным аргументам.

## Оптимизированный код сложнее поддерживать

В качестве обоснования этого аргумента часто приводят нечто вроде вот такого пример:

```javascript
const names = users.map(user => user.name)
                   .filter(name => name[0] === 'a')
                   .join(' ')
```

```javascript
let names = '';
for (let i = 0; i < users.length; i++) {
    const userName = users[i].name;
    if (userName[0] === 'a') {
        names += `${userName} `;
    }
}
const result = names.trimEnd();
```

\- Мол, что тебе легче читать и поддерживать?

Конечно, я отвечаю, что первый читается легче и мой оппонент радостный уходит в закат. Но давайте будем справедливыми - не все оптимизации выглядят именно так. Например, вот ошибка, которую я переодически встречаю при отображении полностью статических компонентов:

```javascript
const TermsAndConditions = () => <ul>{['Don\'t be evil'].map((term, i) => <li key={i}>{term}</li>)}</ul>
```

А это его минимально "оптимизированная" версия:

```javascript
import {rules} from './settings';
const TermsAndConditions = () => <ul>{rules.map((term, i) => <li key={term}>{term}</li>)}</ul>
```

[Скажите, разве это плохо (~С)](https://youtu.be/dlDZmEhFmdQ?t=52)? Я бы не так сказал. Зато теперь у нас статический контент лежит в настройках, а бонусом мы не создаем новый массив на каждый вызов функции (а это время на аллокацию и время на уборку мусора). Можно для него вообще перерендер выключить, но даже так уже не плохо. Спички, скажете вы? Спички, да. Но что насчет вот такой популярной ошибки?

Было:
```javascript
const user = await fetch(userId);
const car = await fetch(carId);
```

Стало:
```javascript
const userRequest = fetch(userId);
const carRequest = fetch(carId);
const [user, car] = await Promise.all([userRequest, carRequest]);
```

Можно было бы еще короче написать, но короче не всегда лучше. Главное не в этом. Главное, что у нас есть код, благодаря которому приложение работает быстрее, а это нам не стоило почти ничего. И таких мест много! Чего стоит один code-splitting. Немного кода и куска JavaScript как небывало. Его больше не надо грузить, парсить. Все просто стало немного быстрее.

К чему я веду - код, который не написан чтобы быть медленным, вполне может работать быстро. Звучит как призыв Капитана Очевидность, но часть проблем с производительностью я исправлял именно так - не ускоряя код, а просто устраняя медленный. Возможно, с этим подходом вы и не попадете в топ 1 самых быстрых сайтов или приложений, но, как известно, 20% усилий приводят к 80% результату, а именно это нам и надо.

## Мы не можем тратить на это время, нам уже в продакшн надо

И наконец последний пункт. Многие считают, что оптимизации производительности — это дорого или по времени (долго, клиент не выделит) или даже по деньгам (нужен спец, бюджета нет, когда-нибудь потом). И это, на самом деле, самый болезненный момент. Если беклог выше [Фудзиямы](https://upload.wikimedia.org/wikipedia/commons/c/c3/FujiWestView2157.jpg) (куда-то меня на восток потянуло), релиз завтра, менеджер пингует каждые два часа с прекрасным "ну как там", заниматься оптимизацией вам будет тяжело. Но есть два "но", которые я хочу проговорить.

Во-первых, многие “оптимизации” — это вовсе не оптимизации. Это просто корректно организованный код, который не тормозит. Да, есть сложные/[не очевидные](https://habr.com/ru/post/449368/) моменты, особенно на стыке приложение/инфраструктура, но, если мы будем грамотно использовать ресурсы которые у нас есть, все будет уже гораздо лучше. В конце концов JavaScript это основной инструмент в веб разработке и понимание того, что ```const really = () => ({})``` создает в памяти новый объект на каждый вызов должно быть очевидно даже коту фронтенд программиста.

А во-вторых, объяснять заказчку или ПМ-у что производительный веб нужен в первую очередь проекту это именно наша задача как специалиста. Я понимаю что вы можете со мной не согласиться, но заказчик вообще не знает, что-такое эти ваши [FCP, LCP, TTI](https://web.dev/vitals/), не знает, что можно [уменьшить latency на 0.3 секунды и заработать на этом 8_000_000 фунтов стерлингов в год](https://www.youtube.com/watch?v=ai-6qwT6ES8&t=462s). У него в голове может просто не быть понимания того, что быстрый веб — это точно такая же фича как, например, список рекомендуемых товаров. Почему? Потому что они оба напрямую влияют на продажи закзичка, а значит и на его доход. И вот этот аргумент заказчик понимает прекрасно.

## Так что же делать

Как ни странно, но я не предлагаю тут же бежать, удалять проект и все переделывать. Я так же не призываю душить ПМ-а или продакта. Скорее всего это не сработает. Вместо этого я предлагаю вам выбрать ключевые метрики производительности вашего приложения и начать их мониторить. А о результатах, информировать лиц, принимающих решения. Если у вас на проекто все хорошо - вам скажут, что команда молодцы и вы со спокойной совестью и документальным подтверждением своих прямых рук пойдете пить нефильтрованное. А если плохо - скорее всего ПМ/Продакт сами придут к вам за решением проблемы и тогда уже вы будете говорить о сроках и объемах.

Ну а о том как мерять есть не одна статья. Можно, например поставить в пайплайн [lighthouse](https://www.npmjs.com/package/lighthouse) и замерять производительность прямо во время сборки/тестов. Можно на крон повесить ежедневные тесты прода с тем же lighthouse или [perfrunner](https://www.npmjs.com/package/perfrunner). Кстати, оба инструмента позволяют вам задать и параметры сети, и замедление процессора. В конце концов можно даже написать свои [тесты производительности на голом puppeteer](https://drag13.io/posts/react-performance-puppeteer-profile/index.html), это тоже не так сложно. Главное, если ваш основной рынок это, например Северная Америка, то не пытайтесь тестириовать ее из Киева, может не ловко получиться.

## Послесловие - преждевременная оптимизация — корень всех зол

Цитата из заглавия известна всем и часто приводится как 0-й аргумент против оптимизации веб приложений. Но с вебом есть один не очевидный нюанс. В вебе пользователь не жалуется, а просто молчаливо уходит. Поэтому, если вы не хотите остаться без пользователей, то оптимизацию я бы начал все-таки по-раньше, во избежание. И тогда все будет хорошо.
























 Причем, если часть из них очевидна, как мой пример выше, то часть может быть уже не столь очевидной. Приведу классический пример из мира реакт:

```jsx
const Btn = ({ txt }) => (
  <button onClick={() => alert("test")} type="button">
    {txt}
  </button>
);
```

Функциональный компонент выполняется(1) всякий раз когда меняется его родитель. Каждое выполнение приводит к созданию объекта который реакт будет использовать для поиска изменившихся свойств, а так же к созданию нового обработчика событий для нажатия мыши. Правда в продакшн сборке обработчик к DOM елементу добавляться не будет, и тем менее, тут явно проделывается излишняя работа. Очевидно что







Конечно, такое мне никто не говорил, хотя бы потому что для такой формулировки нужно самому поседеть за Celeronom или Atomom


слышу, что: на самом деле, в (подставьте сюда текущий год), оптимизации производительности уже не важна.

примерно те же аргументы что я написал выше - поддержка, цена работы и мощность и вот о них я хочу поговорить.



 И тем не менее, каждый раз когда я пишу код, я трачу время на обдумывание того, насколько сильно это отразиться на посетителях моего сайта. Причина этому проста - согласно аналитике большинство из них используют мобильные телефоны для того, что бы сделать заказ в нашем маленьком сервисе. А это значит что они имеет нестабильное хG соедениение (где x находится в пределах 2-4) значительно более ограниченный объем памяти (2-4 гб вместо моих 16) и процессор частотой ____ гц. Поэтоу то что летает у меня - может подтормаживать и раздражать наших пользователей. Учитывая размер минимального чека моего пользователя - я очень не хочу никого раздражать.


Самый частый аргумент который я слышу это конечно же о мощности. Мы работаем с реактом, который изначально писался с прицелом на производительность. Плюс современное мощное железо позволяет многим разработчикам уверенно говорить что все будет работать быстро. Отчасти это правда - небольшие или грамотно написанные приложения на реакте действительно работают быстро. Однако есть нюанс (С). Реакт (да и наверное многие библиотеки и фреймоворки, но реакт в этом моменте лидер) очень легко позволяет убить производительность благодаря своей модели функциональных компонент (которые тем не менее мне безумно нравятся за простоту). Давайте посмотрим на примере:

А ведь на мобильном устройстве у нас будет еще меньше памяти и вычислительных ресурсов.

Однако проблема с производительностью в рантайме это только половина проблемы. Вторая, даже более важная проблема, заключается в скорости загрузки вашего сайта или веб приложения. Вы конечно знаете, что джаваскрипт блокирует рендер документа поэтому все стараются положить его в конец документа или загружать асинхронно используя async/defer конструкции. Вы так же, конечно знаете, что css блокирует загрузку JavaScript (критический CSS). Но знаете ли вы, как размер что несмотря на ваш 100МБ канал, скорость с которой мы получаем первый пакет данных равна _____. Да, потом она вырастает но пользователь ждать не любит. Секунда, вторая и ваш клиент уже ушел, бизнес потерял свою копеечку, а вы, возможно, премию.

И это не все нуюансы. Еще есть шрифты, которые умеют блокировать рендер текста до их загрузки. Еще есть принудительный пересчет стилей (особенно больно для СПА приложений которые обращаются к ___). Есть цена подключения к другим доменам. Есть лимиты на количество параллельных соединений. И все вместе это складывается не только в плохой пользовательский опыт но и  Core Web Vitals метрики из-за которых поисковик может пессимизировать выдачу вашего сайта в поиске. А изображения?

Конечно я не открыл Америку. Эти проблемы известны, и способы лечения с ними известны. Но если вы не будете думать о производительности вашего приложения - вы даже не поймете что ваше приложение болеет.

Ну хорошо. Допустим я убиедил вас, что несмотря на прогресс, мы все еще должны задумываться о производительности наших продуктов. И тут вспылвапет второй аргумент - оптимизированный код сложнее поддерживать.

Вот сравните два куска кода, что легче для чтения и понимания? А где проще допустить ошибку?

```javascript
const names = users.map(user => user.name).filter(name => name[0] === 'a').join(' ')
```

```javascript
let names = '';
for (let i = 0; i < users.length; i++) {
    const userName = users[i].name;
    if (userName[0] === 'a') {
        names += `${userName} `;
    }
}
const result = names.trimEnd();
```

Да, первый код выглядит чище (хотя можно было бы вынести его в отдельную функцию, покрыть тестами, и забыть об этом, но, пускай). Но всегда ли оптимизации выглядят так? Возмем тот же реакт и напишем компонент для покааза списка условий пользования нашего сервиса:

```javascript
const TermsAndConditions = () => <ul>{['Don\'t be evil'].map((term, i) => <li key={i}>{term}</li>)}</ul>
```

Помимо нарушения SRP (статья не об этом), тут есть очевидная проблема. Фактически статичный список будет постоянно ререндериться (хоть, дом обновляться и не будет) и создавать новый массив в памяти на каждый рендер родителя. И скажите спасибо, что строка будет скорее всего интернирована и не будет пересоздаваться. А ведь способов убрать такое поведение есть на любой вкус - тут и `ShouldComponentUpdate false`, PureComponent, React.memo, и на худой конец, просто вынести массив за пределы компоненты куда-то в настройки. Вы скажете что я экономлю на спичках и такая оптимизация практически не даст выиграша и формально будете правы. Но спичка тут, спичка там, и вот у вас уже 500мс для слабых мобильный устройств. А главное это не стоит вам почти ничего. Код не читается хуже, он просто стал немного быстрее. Да и правило Парето никто не отменял, в том числе для performance оптимизаций.

Другими словами - скорее всего вам не понадобится оптимизировать код, который не написан что бы быть медленными.

И вот теперь приходит третий аргумент, который казалось бы пробить не возможно-
оптимизации производительно это дорого и его младший брат "заказчику мы это не продадим".

Давайте начнем с последнего, про заказчика. Сейчас я, наверное, скажу крамольную мысль, но я в нее искренне верю. Объяснять что заказчку (или ПМ-у или другому ответственному лицу) нужен производительный веб это задача ваша как программиста. Потому что только вы знаете, нужно ли ему это действительн и в каком объеме. Заказчик вообще не знает что-такое что такое LGP, LCP, etc и как они влияют. Скорее всего он понятия не имеет об эксперементах гугла и ______. У него в голове просто нет понимания того, что быстрый веб это точно такая же фича как, например, список рекомендуемых товаров. Почему? Потому что они оба напрямую влияют на продажи вашего закзичка и на его доход. И вот этот аргумент заказчик понимает прекрасно.

Ну а что касается первого аргумента тут все еще проще. Простые оптимизации, которых вам вполне могут хватить не требуют ни особой квалификации, ни больших затрат времени. Все что от вас требуется - просто не замедляйте ваше приложение.

Послесловие про 3rd party code.

Знаете как ускорить ваше приложение посто вот не сходя с места и практически не меняя кодовую базу? Посмотрите на посторонний код который вы загружаете на свою страницу. Скорее всего его объем вполне можно уменьшить. Я, например, встречал загрузку GoogleTagManager только для того что бы загрузить потом Google Analytics. Или использование сразу трех! сервисв для аналитики. Уменьшив объем посторонних скриптов вы не только повышаете производительность своего решения, но так же увличиваете его безопасность. Необязательно ломать банк, если можно взломать его доствку.



Представьте себе картину. Релиз через 3 дня. Часть задач не закрыта и пишутся в авральном порядке, команда качества делает регрессию прямо по обновляемому коду до 12 ночи. И тут прихожу я, весь в белом, и говорю - а вот тут у вас код не оптимальный-с, извольте ка переделать. Мне кажется так далеко даже Мильфгард не ездил.


## И что теперь?

Как ни странно, но я не предлагаю тут же бежать, удалять проект и все переделывать. Я так же не призываю душить ПМ-а или кто там у вас отвечает за прибыль проекта в целом. Скорее всего это попросту не сработает. Вместо этого я предлагаю вам выбрать ключевые метрики производительности и начать их мониторить. Ах, да - и конечно-же информировать об этом лиц принимающих решения. Если у вас на проекто все хорошо - все скажут что команда молодцы и вы со спокойной совестью и документальным подтверждением своих прямых рук пойдете пить вио. А если плохо - скорее всего ПМ/Владелец сами придут к вам за решением и тогда уже вы будете говорить о сроках и объемах.

Ну а о том как мерять есть не одна статья. Главное, если ваш основной рынок это, например южная Америка, меряйте оттуда. А то мы это уже проходили. Сервер в Европе, тесты хорошие, а на условной Ямайке все грузится минуту.

 и вторая половина не только важна не меньше, но




 просто на корню благодаря:

* Реакт это библиотека* а не фреймворк
* Функциональные компоненты по-умолчанию выполняются всякий раз когда рендерится их родитель

Наверное мой первый аргумент звучит для вас очень странно однако я прошу вас подумать вот о чем. Всякий раз когда вам нужна дополнительная функциональность, вы идете в npm и ставите дополнительный пакет. Это, конечно, не плохо, но это вырабатывают плохую привычку ставить сторонние решения на каждую, даже небольшую потребность тем самым раздувая ваш бандл. Парадокс в том, что это еще и сильная сторона реакта, т.к. позволяет добавлять исключительно то что нужно, а не все подряд. Ангуляр потратил много времени что-бы убрать из кор модуля не обязательные зависимости.


И хорошо если вы смотрите не только на звезды, а и например на bundlephobia. Но некоторые настолько привыкли к таком

, однако я вижу проблему вот в чем. Когда вам понадобится дополнительная функциональность


(примеры сейчас будут). И что самое грустное - многие примеры кода имеют именно эти проблемы.

Давайте посмотрим на пример №1:

```jsx
const label = ({txt})=> <label>{txt}</label>
```

Дл

 (виртуальный дом, файбер, постоянное уменьшение размера кор библиотеки)



Наверное, примерно так, думали инженеры гугла когда выкатили свою обновленную версию почты, которая отъедала гигабайты памяти и висла.

























 Причем, если часть из них очевидна, как мой пример выше, то часть может быть уже не столь очевидной. Приведу классический пример из мира реакт:

```jsx
const Btn = ({ txt }) => (
  <button onClick={() => alert("test")} type="button">
    {txt}
  </button>
);
```

Функциональный компонент выполняется(1) всякий раз когда меняется его родитель. Каждое выполнение приводит к созданию объекта который реакт будет использовать для поиска изменившихся свойств, а так же к созданию нового обработчика событий для нажатия мыши. Правда в продакшн сборке обработчик к DOM елементу добавляться не будет, и тем менее, тут явно проделывается излишняя работа. Очевидно что







Конечно, такое мне никто не говорил, хотя бы потому что для такой формулировки нужно самому поседеть за Celeronom или Atomom


слышу, что: на самом деле, в (подставьте сюда текущий год), оптимизации производительности уже не важна.

примерно те же аргументы что я написал выше - поддержка, цена работы и мощность и вот о них я хочу поговорить.



 И тем не менее, каждый раз когда я пишу код, я трачу время на обдумывание того, насколько сильно это отразиться на посетителях моего сайта. Причина этому проста - согласно аналитике большинство из них используют мобильные телефоны для того, что бы сделать заказ в нашем маленьком сервисе. А это значит что они имеет нестабильное хG соедениение (где x находится в пределах 2-4) значительно более ограниченный объем памяти (2-4 гб вместо моих 16) и процессор частотой ____ гц. Поэтоу то что летает у меня - может подтормаживать и раздражать наших пользователей. Учитывая размер минимального чека моего пользователя - я очень не хочу никого раздражать.


Самый частый аргумент который я слышу это конечно же о мощности. Мы работаем с реактом, который изначально писался с прицелом на производительность. Плюс современное мощное железо позволяет многим разработчикам уверенно говорить что все будет работать быстро. Отчасти это правда - небольшие или грамотно написанные приложения на реакте действительно работают быстро. Однако есть нюанс (С). Реакт (да и наверное многие библиотеки и фреймоворки, но реакт в этом моменте лидер) очень легко позволяет убить производительность благодаря своей модели функциональных компонент (которые тем не менее мне безумно нравятся за простоту). Давайте посмотрим на примере:

А ведь на мобильном устройстве у нас будет еще меньше памяти и вычислительных ресурсов.

Однако проблема с производительностью в рантайме это только половина проблемы. Вторая, даже более важная проблема, заключается в скорости загрузки вашего сайта или веб приложения. Вы конечно знаете, что джаваскрипт блокирует рендер документа поэтому все стараются положить его в конец документа или загружать асинхронно используя async/defer конструкции. Вы так же, конечно знаете, что css блокирует загрузку JavaScript (критический CSS). Но знаете ли вы, как размер что несмотря на ваш 100МБ канал, скорость с которой мы получаем первый пакет данных равна _____. Да, потом она вырастает но пользователь ждать не любит. Секунда, вторая и ваш клиент уже ушел, бизнес потерял свою копеечку, а вы, возможно, премию.

И это не все нуюансы. Еще есть шрифты, которые умеют блокировать рендер текста до их загрузки. Еще есть принудительный пересчет стилей (особенно больно для СПА приложений которые обращаются к ___). Есть цена подключения к другим доменам. Есть лимиты на количество параллельных соединений. И все вместе это складывается не только в плохой пользовательский опыт но и  Core Web Vitals метрики из-за которых поисковик может пессимизировать выдачу вашего сайта в поиске. А изображения?

Конечно я не открыл Америку. Эти проблемы известны, и способы лечения с ними известны. Но если вы не будете думать о производительности вашего приложения - вы даже не поймете что ваше приложение болеет.

Ну хорошо. Допустим я убиедил вас, что несмотря на прогресс, мы все еще должны задумываться о производительности наших продуктов. И тут вспылвапет второй аргумент - оптимизированный код сложнее поддерживать.

Вот сравните два куска кода, что легче для чтения и понимания? А где проще допустить ошибку?

```javascript
const names = users.map(user => user.name).filter(name => name[0] === 'a').join(' ')
```

```javascript
let names = '';
for (let i = 0; i < users.length; i++) {
    const userName = users[i].name;
    if (userName[0] === 'a') {
        names += `${userName} `;
    }
}
const result = names.trimEnd();
```

Да, первый код выглядит чище (хотя можно было бы вынести его в отдельную функцию, покрыть тестами, и забыть об этом, но, пускай). Но всегда ли оптимизации выглядят так? Возмем тот же реакт и напишем компонент для покааза списка условий пользования нашего сервиса:

```javascript
const TermsAndConditions = () => <ul>{['Don\'t be evil'].map((term, i) => <li key={i}>{term}</li>)}</ul>
```

Помимо нарушения SRP (статья не об этом), тут есть очевидная проблема. Фактически статичный список будет постоянно ререндериться (хоть, дом обновляться и не будет) и создавать новый массив в памяти на каждый рендер родителя. И скажите спасибо, что строка будет скорее всего интернирована и не будет пересоздаваться. А ведь способов убрать такое поведение есть на любой вкус - тут и `ShouldComponentUpdate false`, PureComponent, React.memo, и на худой конец, просто вынести массив за пределы компоненты куда-то в настройки. Вы скажете что я экономлю на спичках и такая оптимизация практически не даст выиграша и формально будете правы. Но спичка тут, спичка там, и вот у вас уже 500мс для слабых мобильный устройств. А главное это не стоит вам почти ничего. Код не читается хуже, он просто стал немного быстрее. Да и правило Парето никто не отменял, в том числе для performance оптимизаций.

Другими словами - скорее всего вам не понадобится оптимизировать код, который не написан что бы быть медленными.

И вот теперь приходит третий аргумент, который казалось бы пробить не возможно-
оптимизации производительно это дорого и его младший брат "заказчику мы это не продадим".

Давайте начнем с последнего, про заказчика. Сейчас я, наверное, скажу крамольную мысль, но я в нее искренне верю. Объяснять что заказчку (или ПМ-у или другому ответственному лицу) нужен производительный веб это задача ваша как программиста. Потому что только вы знаете, нужно ли ему это действительн и в каком объеме. Заказчик вообще не знает что-такое что такое LGP, LCP, etc и как они влияют. Скорее всего он понятия не имеет об эксперементах гугла и ______. У него в голове просто нет понимания того, что быстрый веб это точно такая же фича как, например, список рекомендуемых товаров. Почему? Потому что они оба напрямую влияют на продажи вашего закзичка и на его доход. И вот этот аргумент заказчик понимает прекрасно.

Ну а что касается первого аргумента тут все еще проще. Простые оптимизации, которых вам вполне могут хватить не требуют ни особой квалификации, ни больших затрат времени. Все что от вас требуется - просто не замедляйте ваше приложение.

Послесловие про 3rd party code.

Знаете как ускорить ваше приложение посто вот не сходя с места и практически не меняя кодовую базу? Посмотрите на посторонний код который вы загружаете на свою страницу. Скорее всего его объем вполне можно уменьшить. Я, например, встречал загрузку GoogleTagManager только для того что бы загрузить потом Google Analytics. Или использование сразу трех! сервисв для аналитики. Уменьшив объем посторонних скриптов вы не только повышаете производительность своего решения, но так же увличиваете его безопасность. Необязательно ломать банк, если можно взломать его доствку.



Представьте себе картину. Релиз через 3 дня. Часть задач не закрыта и пишутся в авральном порядке, команда качества делает регрессию прямо по обновляемому коду до 12 ночи. И тут прихожу я, весь в белом, и говорю - а вот тут у вас код не оптимальный-с, извольте ка переделать. Мне кажется так далеко даже Мильфгард не ездил.


## И что теперь?

Как ни странно, но я не предлагаю тут же бежать, удалять проект и все переделывать. Я так же не призываю душить ПМ-а или кто там у вас отвечает за прибыль проекта в целом. Скорее всего это попросту не сработает. Вместо этого я предлагаю вам выбрать ключевые метрики производительности и начать их мониторить. Ах, да - и конечно-же информировать об этом лиц принимающих решения. Если у вас на проекто все хорошо - все скажут что команда молодцы и вы со спокойной совестью и документальным подтверждением своих прямых рук пойдете пить вио. А если плохо - скорее всего ПМ/Владелец сами придут к вам за решением и тогда уже вы будете говорить о сроках и объемах.

Ну а о том как мерять есть не одна статья. Главное, если ваш основной рынок это, например южная Америка, меряйте оттуда. А то мы это уже проходили. Сервер в Европе, тесты хорошие, а на условной Ямайке все грузится минуту.

 и вторая половина не только важна не меньше, но




 просто на корню благодаря:

* Реакт это библиотека* а не фреймворк
* Функциональные компоненты по-умолчанию выполняются всякий раз когда рендерится их родитель

Наверное мой первый аргумент звучит для вас очень странно однако я прошу вас подумать вот о чем. Всякий раз когда вам нужна дополнительная функциональность, вы идете в npm и ставите дополнительный пакет. Это, конечно, не плохо, но это вырабатывают плохую привычку ставить сторонние решения на каждую, даже небольшую потребность тем самым раздувая ваш бандл. Парадокс в том, что это еще и сильная сторона реакта, т.к. позволяет добавлять исключительно то что нужно, а не все подряд. Ангуляр потратил много времени что-бы убрать из кор модуля не обязательные зависимости.


И хорошо если вы смотрите не только на звезды, а и например на bundlephobia. Но некоторые настолько привыкли к таком

, однако я вижу проблему вот в чем. Когда вам понадобится дополнительная функциональность


(примеры сейчас будут). И что самое грустное - многие примеры кода имеют именно эти проблемы.

Давайте посмотрим на пример №1:

```jsx
const label = ({txt})=> <label>{txt}</label>
```

Дл

 (виртуальный дом, файбер, постоянное уменьшение размера кор библиотеки)



Наверное, примерно так, думали инженеры гугла когда выкатили свою обновленную версию почты, которая отъедала гигабайты памяти и висла.