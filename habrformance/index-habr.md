Некоторое время назад я увлекся производительностью веб-приложений, как делать их быстрее, как оптимизировать загрузку и так далее. И пару дней назад решил, почему бы мне не совместить приятное с полезным - посмотреть, как обстоят дела с производительностью нашего Habra. Тем более что команда там сидит наверняка опытная, значит будет интересно, да и наверняка я еще и что-то новое для себя узнаю. Для тех кому интересно узнать что было сделано что бы мы получали контент как можно быстрее - прошу под кат.

<cut/>

## Подготовка

Нам понадобится свежая версия Chrome/Canary работающие в анонимном режиме (проверьте что бы у вас в анонимном режиме не использовались какие-либо аддоны). Во вкладке network нужно установить флаг Disable cache, т.к. нас интересует именно первая загрузка, пока никаких ресурсов в кеше еще нет.

## Этап первый - "По верхам"

Итак мы готовы. Открываем developer tools (если он еще не открыт), переходим на вкладку network, открываем Habr и внизу, смотрим на общие сведения, которые для нас собрал Chrome:

![грузим быстро](https://habrastorage.org/webt/ni/fs/yb/nifsybxewz18qswerh5jubfsn1a.png)

Весь сайт был загружен за 2.02 секунды, что выглядит просто замечательно (учитывая нагрузку Habra). Событие DomContentLoaded(дальше просто DCL) вообще появилось за 1.01 секунды что выглядит еще лучше. При всем при этом, сайт делает 189 запросов и грузит 9.6МБ ресурсов. Это говорит нам о том, что либо команда Хабра - гении (вполне может быть), а статью надо заканчивать прямо тут (и проситься к ним в команду за кофе и печеньки), либо вспомнить что у меня канал 100мб и core i7. Т.е. нужно немного приблизиться к реалиям и хотя бы ограничить ширину канала. Включаем режим Fast 3g и смотрим еще так раз:

![грузим медленнее](https://habrastorage.org/webt/bp/ov/lk/bpovlkvte1ojvmuamwcoki4uniq.png)

DCL ухудшился до 3.48 секунд что все еще достаточно приемлемо. А вот окончательно сайт загрузился за безбожные 54.76 секунды. Теперь все логично - нельзя так просто взять и загрузить почти 10 мегабайт, когда у тебя слабое соединение. Скорее всего, ребята провели хорошую работу что бы максимально быстро показать нам контент (об этом говорит то, что даже в режиме fast3g DCL возникает достаточно быстро), а все не критичное оставили грузиться в фоне. Чуть позже мы это проверим, а теперь давайте посмотрим почему мы грузились так долго. Отсортируем все запросы по времени загрузки: 

![виноватые](https://habrastorage.org/webt/el/jv/uc/eljvucnzbn0d83cd2konxv8ff-8.png)
(кликабельно)

Итак, дольше всего грузятся изображения (топ-7) и один JS - prebid.js. Если мы посмотрим на их размер, можно будет предположить, что именно это есть причина медленной загрузки. 
Однако не надо спешить с выводами, это не всегда так. Например, вы можете загружать изображения из какого-то далекого или перегруженного хранилища, или есть проблемы с DNS или еще что-то. В таком случае, об этом нам подскажет время до отправки первого байта (TTFB) - оно будет аномально длинным. Но тут все проще - TTFB 610ms и 40 секунд загрузки. Значит дело в размере. Давайте полюбуемся на наш TOP 1 (png, 1560Х780, 24bit):

![эх вы...](https://habrastorage.org/webt/61/ts/aj/61tsajb8gnvzqjaw0cg-mqdj32e.png)

На самом деле проблемы с изображениями это проблемы по-большей части нашего с вами траффика. Изображения (в отличии от стилей и скриптов) не блокируют рендер веб-страницы, и поэтому, несмотря на наличие таких тяжеловесов (бывает и хуже, видели), на производительности это почти не сказывается. Хотя, конечно, оптимизация в этом направлении (например перекодировка в jpeg2000 или webp, или прогрессивная загрузка была бы не лишней).

<spoiler title="Про изображения">
Как я писал выше, изображения не блокируют рендер страницы, но они используют на пул соединений, а в http 1.x у нас их ограниченное количество, да и с http 2.x и Chrome тоже не все так просто насколько я знаю. Поэтому даже тут есть шанс, что какое-то изображение может замедлить загрузку синхронного скрипта, а тот, в свою очередь, уже остановит рендер страницы. Так что даже тут не все так просто.
</spoiler>

Давайте посмотрим какие еще ресурсы тянет Хабр - пройдемся по типам и отсортируем по времени загрузки. Начнем с javascript

<spoiler title="Про javascript">
У javascript есть несколько проблем в плане производительности сайта. Во-первых (про это все знают и давно говорят), синхронный js блокирует дальнейший рендер страницы. Т.е. пока мы наш javascript не получим и не выполним, мы будем стоять на месте откладывая момент, когда пользователь увидит что-то полезное. Поэтому все стараются выбросить Js в конец страницы или вообще сделать его асинхронным. Это работает, но не решает вторую проблему, которую приносит нам большой размер javascrip-а. Js это скриптовый язык. Поэтому, браузеру мало его просто скачать - его нужно еще и "понять". И тут, оказывается, что это проблема, потому что слабые процессоры (например в дешевых телефонах или нетбуках или даже хороших ноутах в режиме ограниченной производительности) делают это медленно, блокируя основной поток! Забегая наперед, я покажу пример как асинхронный рекламный скрипт влез в критическую секцию ренедра хабра и пусть немного, но все же попортил производительность. Если кто заинтересовался, вот тут есть очень хорошая статья на [эту тему](https://medium.com/reloading/javascript-start-up-performance-69200f43b201)
</spoiler>

Скриптов хабр грузит много - 1.1 МБ на 40 запросов. Это прямо скажем существенно, это нам еще аукнется и с этим надо что-то делать. Отсортируем наши скрипты "по водопаду". Наша задача - найти скрипты которые загрузились ДО синей линии, так как именно они (вероятнее всего) мешают нам отрисовать сайт как можно быстрее.

Открываем ответ от Хабра с html (важно смотреть именно ответ, так как итоговый html может выглядеть уже совсем по-другому) и проходимся по списку. Как видим - jQuery, raven.js, advertise.js и adriver.js грузится синхронно прямо из head тега (т.е. блокируют вообще все). Gpt и publisher грузятся из head но уже асинхронно (т.е. ничего не блокируют, браузер будет рендерить страницу дальше пока они качаются). Vendors, Main и Math, checklogin грузятся в конце, но синхронно (Т.е. текст уже есть, можем читать, но DCL не появиться пока они не загрузятся). Остальные в начальном ответе не появляются - они добавляются динамически, но это уже другая тема.

Мы нашли те скрипты, которые так или иначе влияют на то, как быстро мы увидим текст на странице. Это первые кандидаты на оптимизацию. В идеале - их нужно сделать асинхронными или поместить как можно позже, чтобы дать браузеру возможность отрисовать хоть что-то. Однако идеал не достижим, так как скорее всего на сайте есть другие скрипты, которые зависят от того же jQuery. Желание как можно раньше загрузить raven - библиотеку для отслеживания разных ошибок, возникающих на клиенте тоже можно понять. А вот advertise.js и adriver.js уже реальные кандидаты на, как минимум переезд вниз страницы, а как максимум еще и в асинхронный режим. Аналогичная история и с Gpt и publisher. Да, они грузятся асинхронно, но, тем не менее они могут (и будут) нам мешать показать контент пользователю как можно раньше. Поэтому их, возможно, тоже можно отправить в самый низ страницы. Если это сделать нельзя - можно попробовать воспользоваться атрибутами [Resource Hints](https://developer.mozilla.org/en-US/docs/Web/HTML/Preloading_content) -  preload/prefetch/dns-prefetch для подсказки браузеру что стоит подгрузить.

Теперь отсортируем список по размеру файла. Видим скрипт, который грузится дважды (pubads). Его вероятно, стоит убрать. Замечаем, что prebid.js грузится из папки not-for-prod (хм?)

![хренак-хренак-и-в-продакшн](https://habrastorage.org/webt/4e/su/7w/4esu7wsvwdpgmbw8nscc_sqcgmo.png)

Для очистки совести проверяем что все скрипты минифицированны. Внезапно, оказались не минифицированными микро скрипты check-login.js и adriver.js. Особенно порадовал контент последнего:

![нас-не-догонят](https://habrastorage.org/webt/6q/nv/q8/6qnvq8dimcd_5m3w77mr3mkjlea.png)

И со скриптами можно временно заканчивать.

###Стили

<spoiler title="Про стили">
Со стилями все тоже не так просто. Во-первых, синхронная загрузка стилей тоже блокирует основной поток...
</spoiler>

Вот стили которые загружает Habr:

![](https://habrastorage.org/webt/nm/6y/a7/nm6ya7qcp1bdqcp5sl2fiingrp8.png)
(кликабельно)

Как видим, их всего три, причем второй и третий грузятся в отдельном фрейме. А вот первый набор стилей критично важен для всего сайта. И загружали мы его очень долго. Почему? Во-первых долго ждали ответа от сервера (TTFB 570ms, мы к нему еще вернемся в третьей секции), во вторых долго грузили 713ms. Что тут можно сделать. Первое и самое простое - попробовать добавить атрибут preload. Это даст подсказку браузеру начать загружать css как можно раньше. Второй вариант выделить критический css и внедрить его непосредственно в веб страницу, а остатки загрузить асинхронно. Это приведет к росту размера страницы (но она и так не маленькая 5кб уже никого не спасут) и возможной перерисовке лаяута (потеря времени), но можно попробовать.

Шрифты даже показывать не буду. Он там один и грузится прямо с сервера Habr (что вызывает уже немного другие вопросы).

На этом обзорную часть разбора сайта можно считать завершенной. Время идти глубже.

## Этап второй - "Ручной режим"

Теперь давайте посмотрим на то, как же в действительности происходит построение сайта с точки зрения браузера.

Переходим на вкладку профайлинга. Проверяем что стоит slowdown fast3g (потому запустим еще раз, но без ограничений) и запускаем. В первую очередь нас интересует все что происходит до события FirstMeaningfullPaint (FMP), и, на всякий случай DCL. Выделяем область от старта до FMP и смотрим на summary chart. 

![](https://habrastorage.org/webt/1s/nb/qi/1snbqidqssgm4mxoulzysms7swu.png)

Все происходит довольно быстро - 2.161 сек до FMP (было быстрее но, видимо, что-то поменялось), однако как видно, большую часть времени браузер простаивал. Полезная нагрузка заняла всего 14% времени(около 310ms). В идеале, основной поток браузера работает постоянно - парсит html, css, строит layout, выполняет js. А тут - ничего. Почему? Потому что браузеру было просто нечем заняться. Помните мы урезали траффик? Браузер разослал запросы и теперь просто ждет их выполнения. Если мы откроем верхний чарт network все станет сразу понятно. В 2029 браузер увидел main.bundle.css, отправил запрос на его получение и стал ждать. В это время пресканер (хром умный, он умеет забегать вперед) обнаружил, что внизу есть синхронные скрипты и не дожидаясь пока придет css отправил запрос на получение скриптов. Потом загрузились advertise и adriver (но мы помним, что пока CSSOm не создан, трогать JS нельзя),поэтому их даже не стали парсить. После этого загрузились gpt и raven, Но css все еще грузился, поэтому их тоже никто их не трогал. Наконец-то загрузился css который браузер распарсили за 12ms и тут же пошел парсить внедренный в страницу JS. Потом снова остановился почти на 150 мс (ждал пока же мы догрузим jquery.min.js). И после этого уже взялся за работу всерьез - разобрался с загруженным jquery (20мс), распарсил raven.js(4мс), распарсил почти всю страницу (36мс), пересчитал стили (28мс), рассчитал лаяут (78ms + 8ms) и, наконец, за ms раскрасил нам страницу. Тут мы и получили наш FMP. Дальше мы парсим страницу, парсим скрипты - привет никому не нужные (publishertag.js, gpt.js которые влезли в main thread до DCL), немного поигрались со стилями (что вызвало небольшую потерю времени из-за перерасчета лаяута) и начали ждать vendors.bundle.js (он, кстати, минифицирован, несмотря на отсутствие min). На то что бы дождаться вендоров мы, почти вхолостую, потратили еще около 1.1 секунды. Правда параллельно с ним мы загружали еще и main.bundle.js (который, кстати, загрузился быстрее), поэтому не все так плохо. Дальше все снова пошло хорошо. Распарсили вендоров, распарсили основной бандл, распарсили Math.Jax, и наконец то допарсили страницу и получили DCL! Правда тут же сработал какой-то хендлер который на моем I7 остановил основной поток на 80мс (т.е. сайт как бы подвис на 80ms). Сейчас мы этого почти не заметили, но на слабом процессоре, теоретически, это может быть заметно.

Что тут можно сказать. Опять-таки, несмотря на то как это выглядит все достаточно неплохо. Основные проблемы нам доставили:

* Большой простой браузера
* Долгая загрузка CSS которая отложила работу с критическим js
* Синхронная загрузка jQuery, vendors и main бандлов которые остановили рендер страницы

Что с этим можно сделать мы уже обсуждали:

* Preload для CSS и возможно некоторых JS
* Уменьшить или заинлайнить CSS
* Попытаться вообще выбросить скрипты из синхронной загрузки

Теперь давайте повторим тоже самое уже без ограничений на ширину канала. Картина уже гораздо лучше: 0.452 секунды до FMP, простой всего! 13ms. DCL - 953ms, простой 15ms. Вот как выглядит загрузка моей мечты. Вот только это получилось из-за того, что открыл новую вкладку и не убрал кеширование. Попробуем то же самое, но без кэша:

![](https://habrastorage.org/webt/g5/ji/5q/g5ji5qscsjud50jdqkoazqoxsga.png)

Все тоже достаточно хорошо, FMP - 1689, полезная нагрузка выросла из 14% до 45%. Но, тут неожиданно много времени ушло на Rendering - 400ms для FMP. Из них 200ms ушло на пересчет стилей и перерасчет лаяута. Причем самое обидное то, что вычислить паршивца который в этом виноват не так просто. Перед тем как начать пересчитывать стили отрабатывает raven.js но с чего бы системе для ловли ошибок клиента лезть в стили непонятно. Network намекает на шрифты, но это не доказуемо. В общем без кода разобраться сложно.

Кстати, еще один интересный момент. Помните рекламные скрипты - gpt.js и publishertag.js которые упоминались в первой части? Теперь можно заметить, что несмотря на их асинхронность они таки смогли (пусть и немного) но испортить нам статистику. Потому что асинхронные скрипты выполняются после загрузки самого скрипта, и, как следствие, могут остановить основной поток браузера на время своего парсинга и выполнения, что и произошло в 3309.

Итак, ручную разборку мы сделали. Пора расчехлять автоматику.

## Этап третий - "С него надо было начинать"

Не будем далеко ходить, в том же devtools откроем вкладку audit и запустим LightHouse со следующими настройками: desctop, performance only, nothrotling, clear storage. Немного подождав (не уходите со страницы на которой проходит аудит и вообще ничего не делайте) получаем фантастические цифры (даже с отключенным кэшем)

![](https://habrastorage.org/webt/cg/cu/rc/cgcurczrbd7r4xhjqrtqgw-pj5s.png)

Мне даже кажется, что для того, что бы я увидел эти цифры кто-то специально и не слабо потрудился.

При этом lighthouse все-таки жалуется на:

* Устаревший формат изображений (предлагает использовать webp, jpeg2000, etc)
* Количество DOM node – их аж слишком много: 2533
* Слишком интенсивный траффик
* Не корректную политику кеширования - отсутствуют заголовки кеширования на 23 ресурсах
* Использование document.write 

Тут все понятно. Изображения пережать и перекодировать, DOM - найти кто генерит так много node (и скорее всего плюнуть), выставить кеширование на статические ресурсы, и оторвать document.write-у его writer (если это наш скрипт) (Как легко такое говорить, а на деле это конечно приличный кусок работы)

Теперь попробуем запустим тоже самое, но уже ограничив ширину канала на fast3g и, внимание установив четырехкратное замедление процессора (прощай I7, привет celeron):

![](https://habrastorage.org/webt/td/ei/3j/tdei3jxtwbcvda5csqvvmgz2tua.png)

Как видим все стало резко хуже:

* Значительно выросли проблемы, связанные с изображениями. LH снова предлагает использовать next-gen форматы изображения, но теперь, по его мнению, это сэкономит нам 11 условных секунд
* Выросла проблема с блокирующими рендер ресурсами. Причем тут всплыли два синхронных микроскрипта adriver.js и advertise.js по 50байт каждый, о которых я уже говорил в первой части.
* Появилось предложение порезать CSS с намеком на то, что используется всего 5kb из 45kb.
* Впервые появилась проблема слишком загруженного main thread. Мы порезали вычислительные мощности и браузер захлебнулся в javascript - (8.5 секунд для script evaluation из них 2186ms ушло на raven.js). Не слабо да?

Какие выводы можно вынести отсюда? Хабр хорошо работает на быстром интернете и мощных машинах. Смещение в сторону чего-то по-бюджетнее может вызвать проблемы. Проблемы вызваны:

* Большими изображениями
* Большим объёмом DOM
* Большим количеством JavaScript на странице.

Было сделано очень много что бы эти проблемы не мешали быстрому появлению контента, однако для слабых машин это все еще будет проблема (например, блокирующий raven.js и другие).

И наконец, давайте выйдем за пределы консоли разработчика, и попробуем еще один известный инструмент - [https://www.webpagetest.org/](https://www.webpagetest.org/)

Он замечателен многим - и подробными графиками, и подсказками, и настройками. Но что у него еще есть хорошего - он позволяет вам выбрать локацию, из которой вы якобы смотрите сайт. Все мы помним, что Habr стал интернациональным. Так давайте посмотрим, как Habr будет грузиться, например из Аргентины. Конечно, был бы у меня доступ к метрикам, я бы выбрал более релеватную локацию, а так - будет БуэносАйрес.

И для чистоты эксперимента используем https://habr.com (без ru/en постфикса). 

Здесь все очень подробно. Можно посмотреть сколько времени (и кому) требовалось что бы отрезолвить DNS (500ms для основной страницы), сколько ушло на установку соединение, ssl и так далее. Тут же видно, что мы потратили 1150ms только на переадресацию c основной страницы на англоязычную версию (повод посмотреть почему). Кстати, переадресаций оказывает довольно много (больше всего этим грешит habrastorage).  Можно так же посмотреть злополучный main.bundle.css - оказывается, это первое обращение к dr.habracdn.net что, приводит к необходимости выполнить dns lookup (36ms). Плюс SSL negotiation 606 ms, плюс TTFB 601ms, плюс еще загрузка. В общем не быстро. Но не смотря на все это DCL - 4100ms или около того, что тоже радует. Еще есть отличная вкладка image analysis которая, показывает, как и сколько можно сэкономить если перепожать изображения. Фото какого-то рыжего котейки в PNG весит 1.4МБ, а в webp + downscaling (да читерство, но все же) - 17.7 KB. Для сравнения, фото в таком же разрешении, но все еще в png весит 154кб. В общем только об этом инструменте можно писать отдельную статью. Но, если в общем, что мы можем вынести отсюда:

* Потеряли около двух секунд на начальной загрузке страницы (и это при том, что потом мы ее загрузили за несколько милисекунд, т.е. канал был просто шикарным). 
* Я увидели большое количество переадресаций. Это ест время, с этим надо разбираться.
* Увидели довольно длинный SSL negotiation 200-400 ms. Ну как, длинный, в принципе это нормальное время, но Habr делает уж очень много запросов так что в сумме получается приличное время.
* Увидели долгий TTFB (webpagetest даже поставил нам F за это) 
* Увидели огромнейший чарт загрузок который позволяет оценить, насколько большое количество запросов делает Habr (и при этом все равно основной контент отдается довольно быстро)

##Выводы

* Сайт перегружен. Большой DOM, большое количество рекламных скриптов, большое количество запросов.
* Есть проблемы с изображениями. Большой размер, неоптимальный формат. Все это ест наш с вами трафик и долго грузится.
* Есть проблемы с habrastorage и переадресациями
* Сайт быстро рендериться на хорошем соединение и мощной машине, но все довольно быстро ухудшается с уменьшением канала и падением производительности процессора. (Плюс у меня хорошая видеокарта, я не пробовал ее отключать, возможно там тоже что-то вылезет)
* При всем при этом, очевидно, что проведена хорошая работа по оптимизации. Сайт достаточно быстро грузит основной текст, остальное происходит уже после того, как мы видим текст. 

Итого: многое сделано, но еще есть куда расти и улучшаться. И поменьше бы трекеров/аналитики/рекламы, но это уже скорее мечты.

<spoiler title="Отступление про "колхоз"">
Я думаю, что все понимают, что, если по-честному, моя "аналитика" это колхоз. Настоящая аналитика делается немного не так. По-хорошему, нужно развернуть выделенный сервер, в который никто не будет ничего писать (а то пока я писал статью у меня все время цифры менялись из-за прыгающей нагрузки и новых статей), эмулировать релевантную нагрузку, с релевантными задержками и только тогда начать что-то профилировать. И тем более что-то менять. Потому что иначе вы выскажете предположение, (например, что нужно добавить preload на CSS), добавите, задеплоите а потом окажется что нагрузка в этот момент резко выросла и тот же стиль нам сервер отдал уже на 500ms позже. И окажется что preload плохой - он все только сделал хуже. А уж автор и вовсе редиска. Иными словами, перед любыми экспериментами нам нужна максимально стабильная среда. Это раз. Второе - никогда не надо лезть глубоко (например, в профилирование) с самого начала. Сперва запустите инструментарий (несколько). Соберите отчеты, посмотрите, что максимально хорошего можно сделать за минимальное время. Попробуйте сделать это. Если получиться, возможно вам уже этого хватит. Например у вас css.bundle весит  250kb, а в реальности вам нужно 15 (кстати легко, заимпортили весь бутстрап, а нужна только сетка или вообще normalize, или даже не нужен, остался от предшественников!) Уменьшили размер css и вуаля! Пол секунды выиграли за час работы. Это два. И наконец, всегда проверяйте. Казалось бы, заинлайнил стили, все должно стать лучше, а стало хуже. А почему? А потому что в стилях 50kb base64 картинок, а наша страница всего грузит 200кb ресурсов. Просто помните, что тут нет серебрянной пули и универсальных сценариев. И последнее, пусть оно и противоречит предыдущему предложению. Если у вас не сложный сайт (или даже статика) просто мониторьте TTFB (проблемы с сервером), размер загружаемых ресурсов (привет логотипам за 2MB) и не давайте доступ к Google Tag Manager-у кому попало. И все у вас будет хорошо.
</spoiler>

### Полезные ссылки
* https://medium.com/web-standards/performance-metrics-ff23c213164e
* https://medium.com/reloading/javascript-start-up-performance-69200f43b201
* https://docs.google.com/presentation/d/1Lq2DD28CGa7bxawVH_2OcmyiTiBn74dvC6vn2essroY/edit#slide=id.g1a504e63c9_7_77
* https://www.2dogsdesign.com/webpagetest-waterfall/
* [webpagetest](https://www.webpagetest.org/result/190601_F9_f0f3b815c240efc7ba3b39b30bf193f9/1/details/#waterfall_view_step1)